<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Pierre-Alexandre Kamienny</title>

  <meta name="author" content="Pierre-Alexandre Kamienny">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:67%;vertical-align:middle">
              <p style="text-align:left">
                <name>Pierre-Alexandre Kamienny</name>
              </p>
              <p><a href="https://www.linkedin.com/in/pakamienny/" target="_blank"> LinkedIn</a> &nbsp
                <a href="https://twitter.com/pa_kamienny" target="_blank"  >Twitter</a> &nbsp
               <a href="https://scholar.google.com/citations?user=OT08RqsAAAAJ&hl=fr&oi=sra" target="_blank">Scholar</a></li><p></p>
            </p>
              <p>&nbsp
              </p>
              <p>
              </p>
              <p style="text-align:justify"> <font size=3px > 
              I am a final-year PhD student @{Meta AI, Sorbonne University} working on <b>efficient adaptation of RL agents to unseen tasks</b>.
              Recently, I have used <b>large language models</b> to regress data manipulating math symbols (<b>symbolic regression</b>) with the hope to make symbolic regressors fast and accurate enough to be applied to model-based RL as <b>intepretable world models</b>. <br>
              I am advised by François Charton (Meta AI), Sylvain Lamprier (now at Université d'Angers), and previously Ludovic Denoyer (now at Ubisoft). </font></p>
              </p>
            </td>
            <td style="padding:2.5%;width:45%;max-width:45%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/photo.jpg" class="hoverZoomLink">
              with a <a href="https://www.google.com/search?q=levi+ackerman" target="_blank"> Livaï</a> shirt and best-ever tan
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p style="text-align:justify">
                <font size=3px> My primary research interest is reinforcement learning (RL), particularly enabling RL agents to efficiently adapt to unseen tasks (meta/multi-task RL) by learning "nice" task representations (resp. good coverage policies) in the presence (resp. absence) of training rewards.
                <br> As the dynamics of control tasks are commonly governed by physical laws, I embarked upon the quest of developing RL agents that explicitly model dynamics with equations as I believe that it can enable prior knowledge and/or inductive bias injection, sample efficiency gains, better domain randomization (à-la-Sim2Real) and risk-control thanks to interpretability...
                Practically, this involves using symbolic regression (SR), the search of analytic expressions composed of mathematical operators, e.g. cos, exp, constants and variables.
                Due to the lack of SR algorithms that infer accurate expressions in reasonable time, 
                I have worked on developing transformer-based models, trained on synthetically-generated datasets, that search with order of magnitudes less time. 
                </font>
              </p> <p></p> 

            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Latest news</heading>
            <p>
              <font size=3px>
              <a href="https://arxiv.org/abs/2302.11223" target="_blank"> Deep Generative Symbolic Regression with Monte-Carlo-Tree-Search </a> </b> 
              and <a href="https://arxiv.org/abs/2304.10336v1" target="_blank"> Controllable Neural Symbolic Regression </a> both got accepted to ICML 2023!
            </font>
            </p>
          </td>
        </tr>
      </tbody></table>
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Misc</heading>
            <p>
              <font size=3px>
              <ul>
                  <li> Interned at Facebook AI Research Paris, Nokia Bell Labs and Neoxia.</li>
                  <li> Studied CS at the University of Oxford (Keble College) & CentraleSupélec.
                  <li> Practice street-lifting, a sport where you need to {muscle-up, pull-up, dips, squat} with as much additional weights as you can. Current PRs are respectively {20, 55, 102.5, 155}.
                  <li> Practice urban exploration & rooftoping in Paris!
                  <li> <b> Email</b>: &nbsp pakamienny <i>at</i> meta <i>dot</i> com </li>
              </ul>
            </font>
            </p>
          </td>
        </tr>
      </tbody></table>

        <table style="width:110%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>

            <td style="padding:20px;width:110%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
                <ul>
                  
                   <li><a href="https://arxiv.org/abs/2302.11223" target="_blank"> <b>Deep Generative Symbolic Regression with Monte-Carlo-Tree-Search</b> </a> 
                    <br> <b>Pierre-Alexandre Kamienny</b>, Guillaume Lample, Sylvain Lamprier, Marco Virgolin</font> </li> <p></p>
             
          
                  <li><a href="https://openreview.net/pdf?id=Dzt-AGgpF0" target="_blank"> <b>Controllable Deep Symbolic Regression</b> </a> 
                  <br> Tommaso Bendinelli, Luca Biggio, <b>Pierre-Alexandre Kamienny</b>.
                  <br> <font style="color:RGB(60, 0, 60);"> International Conference on Machine Learning <b>(ICML)</b>,  Workshop on "AI for Science", 2022</font> </li> <p></p>
                    
                  
                  <li><a href="https://arxiv.org/abs/2204.10532" target="_blank"> <b> End-to-end symbolic regression with transformers </b> </a> 
                  <br> <b>Pierre-Alexandre Kamienny</b>*, Stéphane d’Ascoli*, Guillaume Lample, Francois Charton.
                  <br> <font style="color:RGB(60, 0, 60);"> Neural Information Processing Systems <b>(NeurIPS)</b>, 2022 <br>
                    <a href="https://symbolicregression.metademolab.com/" target="_blank"> <b>Demo </b> 
                    </font> </li> <p></p>

                  <li><a href="https://arxiv.org/abs/2201.04600" target="_blank"> <b>Deep symbolic regression for recurrence prediction </b> </a> 
                  <br> Stéphane d’Ascoli*, <b>Pierre-Alexandre Kamienny</b>*, Guillaume Lample, Francois Charton.
                  <br> <font style="color:RGB(60, 0, 60);"> International Conference on Machine Learning <b>(ICML)</b>, 2022 <br>
                  <a href="https://symbolicregression.metademolab.com/" target="_blank"> <b>Demo </b> &
                  <a href="https://www.youtube.com/watch?v=1HEdXwEYrGM&ab_channel=YannicKilcher" target="_blank"> <b>Video by Yannic Kilcher</b></font>  </li> <p></p>

                  <li><a href="https://arxiv.org/abs/2110.14457" target="_blank"> <b>Direct then Diffuse: Incremental Unsupervised Skill Discovery for State Covering and Goal Reaching</b> </a> 
                  <br> <b>Pierre-Alexandre Kamienny</b>*, Jean Tarbouriech*, Sylvain Lamprier, Alessandro Lazaric, Ludovic Denoyer.
                  <br> <font style="color:RGB(60, 0, 60);">  International Conference on Learning Representations <b>(ICLR)</b>, 2022</font> </li> <p></p>

                  <li><a href="https://arxiv.org/abs/2003.06709" target="_blank"> <b>FACMAC: Factored multi-agent centralised policy gradients</b> </a> 
                  <br>Bei Peng, Tabish Rashid, Christian Schroeder de Witt, <b>Pierre-Alexandre Kamienny</b>, Philip Torr, Wendelin Böhmer, Shimon Whiteson.
                  <br> <font style="color:RGB(60, 0, 60);"> Neural Information Processing Systems <b>(NeurIPS)</b>, 2021</font> </li> <p></p>

                </ul>
              </p>
             <heading>Pre-prints</heading>
              <p>
                <ul>
      
                  <li><a href="https://arxiv.org/abs/2005.02934" target="_blank"> <b>Learning adaptive exploration strategies in dynamic environments through informed policy regularization</b> </a> 
                    <br> <b>Pierre-Alexandre Kamienny</b>, Matteo Pirotta, Alessandro Lazaric, Thibault Lavril, Nicolas Usunier, Ludovic Denoyer.</font> </li> <p></p>
                </ul>
              </p>
              <heading>Workshops</heading>
              <p>
                <ul>
                  <li><a href="https://openreview.net/pdf?id=yeF6cyYU7W" target="_blank"> <b>Symbolic Model-Based Reinforcement Learning</b> </a> 
                  <br> <b>Pierre-Alexandre Kamienny</b>, Sylvain Lamprier. 
                  <br> <font style="color:RGB(60, 0, 60);"> International Conference on Machine Learning <b>(ICML)</b>,  Workshops on "AI for Science" & "Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems"
                    ”, 2022</font> </li> <p></p>

                  <li><a href="https://openreview.net/pdf?id=pTZ6EgZtzDU" target="_blank"> <b>Meta-Reinforcement Learning With Informed Policy Regularization</b> </a> 
                  <br> <b>Pierre-Alexandre Kamienny</b>, Matteo Pirotta, Alessandro Lazaric, Thibault Lavril, Nicolas Usunier, Ludovic Denoyer.
                  <br> <font style="color:RGB(60, 0, 60);"> International Conference on Machine Learning <b>(ICML)</b>,  Workshop on "Inductive Biases, Invariances and Generalization in RL", 2020</font> </li> <p></p>
  
                  <li><a href="https://arxiv.org/abs/2005.09220" target="_blank"> <b>Privileged information dropout in reinforcement learning</b> </a> 
                  <br> <b>Pierre-Alexandre Kamienny</b>, Kai Arulkumaran, Feryal Behbahani, Wendelin Boehmer, Shimon Whiteson. 
                  <br> <font style="color:RGB(60, 0, 60);">  International Conference on Learning Representations <b>(ICLR)</b>,  Workshop on "Beyond tabula rasa in RL", 2020</font> </li> <p></p>
  
                </ul>
              </p>
             
                <ul>
 </li>
                </ul>
            </td>
          </tr>
        </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <font style="color:RGB(200, 200, 200);">Website template from <a href="https://github.com/jonbarron/jonbarron_website" target="_blank"   style="color:RGB(200, 200, 200);">here</a></font>
              </p>
            </td>
          </tr>
        </tbody></table>


</body>


</html>
